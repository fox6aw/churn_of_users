{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из алгоритмов машинного обучения я решил выбрать: логистическую регресию, случайный лес и градиентный бустинг."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn import pipeline as pl\n",
    "from sklearn.preprocessing import MinMaxScaler, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "import category_encoders as ce\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаю данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var8</th>\n",
       "      <th>Var9</th>\n",
       "      <th>Var10</th>\n",
       "      <th>...</th>\n",
       "      <th>Var222</th>\n",
       "      <th>Var223</th>\n",
       "      <th>Var224</th>\n",
       "      <th>Var225</th>\n",
       "      <th>Var226</th>\n",
       "      <th>Var227</th>\n",
       "      <th>Var228</th>\n",
       "      <th>Var229</th>\n",
       "      <th>Var230</th>\n",
       "      <th>churn_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3052.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>vr93T2a</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fKCe</td>\n",
       "      <td>02N6s8f</td>\n",
       "      <td>xwM2aC7IdeMC0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1813.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6hQ9lNX</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ELof</td>\n",
       "      <td>xb3V</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>55YFVY9</td>\n",
       "      <td>mj86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>catzS2D</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FSa2</td>\n",
       "      <td>ZI9m</td>\n",
       "      <td>ib5G6X1eUxUn6</td>\n",
       "      <td>mj86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1533.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>e4lqvY0</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>xb3V</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>686.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>MAz3HNj</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WqMG</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 231 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Var1  Var2  Var3  Var4  Var5    Var6  Var7  Var8  Var9  Var10  ...  \\\n",
       "0   NaN   NaN   NaN   NaN   NaN  3052.0   NaN   NaN   NaN    NaN  ...   \n",
       "1   NaN   NaN   NaN   NaN   NaN  1813.0   7.0   NaN   NaN    NaN  ...   \n",
       "2   NaN   NaN   NaN   NaN   NaN  1953.0   7.0   NaN   NaN    NaN  ...   \n",
       "3   NaN   NaN   NaN   NaN   NaN  1533.0   7.0   NaN   NaN    NaN  ...   \n",
       "4   NaN   NaN   NaN   NaN   NaN   686.0   7.0   NaN   NaN    NaN  ...   \n",
       "\n",
       "    Var222      Var223  Var224  Var225  Var226   Var227         Var228  \\\n",
       "0  vr93T2a  LM8l689qOp     NaN     NaN    fKCe  02N6s8f  xwM2aC7IdeMC0   \n",
       "1  6hQ9lNX  LM8l689qOp     NaN    ELof    xb3V     RAYp        55YFVY9   \n",
       "2  catzS2D  LM8l689qOp     NaN     NaN    FSa2     ZI9m  ib5G6X1eUxUn6   \n",
       "3  e4lqvY0  LM8l689qOp     NaN     NaN    xb3V     RAYp  F2FyR07IdsN7I   \n",
       "4  MAz3HNj  LM8l689qOp     NaN     NaN    WqMG     RAYp  F2FyR07IdsN7I   \n",
       "\n",
       "   Var229  Var230  churn_labels  \n",
       "0     NaN     NaN             0  \n",
       "1    mj86     NaN             0  \n",
       "2    mj86     NaN             0  \n",
       "3     NaN     NaN             1  \n",
       "4     NaN     NaN             0  \n",
       "\n",
       "[5 rows x 231 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_data = pd.read_csv('orange_small_churn_data.txt')\n",
    "churn_data['churn_labels'] = pd.read_csv('orange_small_churn_labels.txt', header=None)\n",
    "churn_data['churn_labels'] = churn_data['churn_labels'].apply(lambda x: 0 if x == -1 else 1)\n",
    "\n",
    "churn_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    37024\n",
       "1     2976\n",
       "Name: churn_labels, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_data['churn_labels'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отделю от данных часть на которой в последствии проверим алгоритм на переобучение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, holdout_data = model_selection.train_test_split(churn_data.to_numpy(), test_size=0.2, random_state=0,\n",
    "                                                         stratify=churn_data['churn_labels'].values)\n",
    "labels = data[:,-1].astype(np.int32)\n",
    "holdout_labels = holdout_data[:,-1].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "      <th>224</th>\n",
       "      <th>225</th>\n",
       "      <th>226</th>\n",
       "      <th>227</th>\n",
       "      <th>228</th>\n",
       "      <th>229</th>\n",
       "      <th>230</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>76DJixu</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>szEZ</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1134.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>dLSJu87</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Xa3G</td>\n",
       "      <td>6fzt</td>\n",
       "      <td>F2FcTt7IdMT_v</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3059.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>C7Jqqb8</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ELof</td>\n",
       "      <td>Aoh3</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>am7c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>945.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>catzS2D</td>\n",
       "      <td>M_8D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ELof</td>\n",
       "      <td>Xa3G</td>\n",
       "      <td>ZI9m</td>\n",
       "      <td>ib5G6X1eUxUn6</td>\n",
       "      <td>am7c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>749.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>eIi2qo0</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PM2D</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 231 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2    3   4       5     6   7   8   9  ...      221         222  \\\n",
       "0 NaN NaN NaN  0.0 NaN     NaN   NaN NaN NaN NaN  ...  76DJixu  LM8l689qOp   \n",
       "1 NaN NaN NaN  NaN NaN  1134.0   7.0 NaN NaN NaN  ...  dLSJu87  LM8l689qOp   \n",
       "2 NaN NaN NaN  NaN NaN  3059.0  21.0 NaN NaN NaN  ...  C7Jqqb8  LM8l689qOp   \n",
       "3 NaN NaN NaN  NaN NaN   945.0  14.0 NaN NaN NaN  ...  catzS2D        M_8D   \n",
       "4 NaN NaN NaN  NaN NaN   749.0   7.0 NaN NaN NaN  ...  eIi2qo0  LM8l689qOp   \n",
       "\n",
       "   223   224   225   226            227   228  229  230  \n",
       "0  NaN   NaN  szEZ  RAYp  F2FyR07IdsN7I   NaN  NaN    0  \n",
       "1  NaN   NaN  Xa3G  6fzt  F2FcTt7IdMT_v   NaN  NaN    0  \n",
       "2  NaN  ELof  Aoh3  RAYp  F2FyR07IdsN7I  am7c  NaN    0  \n",
       "3  NaN  ELof  Xa3G  ZI9m  ib5G6X1eUxUn6  am7c  NaN    0  \n",
       "4  NaN   NaN  PM2D  RAYp  F2FyR07IdsN7I   NaN  NaN    0  \n",
       "\n",
       "[5 rows x 231 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_holdout = pd.DataFrame(holdout_data)\n",
    "churn_holdout.to_csv('holdout_data.csv',index=False)\n",
    "\n",
    "churn_holdout_test = pd.read_csv('holdout_data.csv')\n",
    "churn_holdout_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отброшу признаки, значения которых на всех объектах nan, признаки с неуникальными значениями, и признаки линейнозависящие от других признаков. Далее разобью признаки на числовые и категориальные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(230)\n",
    "indices = indices[~(churn_data.iloc[:,:-1].isnull().all() + churn_data.iloc[:,:-1].nunique() == 1)]\n",
    "line_dependent = np.array([65,155,90,147,127,104,221,213])\n",
    "indices = np.setdiff1d(indices, line_dependent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_indices_of_feature(indices):\n",
    "    \"\"\" Split indices on indices of numerical features and indices of categorial features.\n",
    "    \n",
    "        Keyword arguments:\n",
    "            indices -- 1-d array\n",
    "        Returns:\n",
    "            numeric indices -- 1-d array, consisting of indexes of numerical features.\n",
    "            categoric indices -- 1-d array, consisting of indexes of categorical features.\n",
    "    \"\"\"\n",
    "    return (indices[indices < 190], indices[indices>=190])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_indices, cat_indices = split_indices_of_feature(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построю pipeline для логистической регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = pl.Pipeline(steps=[\n",
    "    ('feature_processing', pl.FeatureUnion(transformer_list=[\n",
    "        #numeric\n",
    "        ('numeric_variable_processing',pl.Pipeline(steps=[\n",
    "            ('selecting', FunctionTransformer(lambda data: data[:,num_indices],validate=False)),\n",
    "            ('imputing_nan_values', SimpleImputer(missing_values=np.nan,strategy='median',fill_value=0)),\n",
    "            ('converting', FunctionTransformer(lambda data: data.astype(np.float64),validate=False)),\n",
    "            ('scaling', MinMaxScaler())\n",
    "        ])),\n",
    "        #categorial\n",
    "        ('categorial_variable_processing',pl.Pipeline(steps=[\n",
    "            ('selecting', FunctionTransformer(lambda data: data[:,cat_indices],validate=False)),\n",
    "            ('imputing_nan_values', SimpleImputer(missing_values=np.nan, strategy='constant', fill_value='na')),\n",
    "            ('encoding', ce.CatBoostEncoder())\n",
    "        ]))\n",
    "    ])),\n",
    "    ('classifier', LogisticRegression(solver='lbfgs',max_iter=1000, class_weight='balanced'))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобью данные 10 раз на 5 фолдов с сохранением баланса классов, посчитаю roc_auc, по roc кривой подберу оптимальный порог и вычислю все метрики на каждом фолде. Выведу среднее метрик по всем фолдам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cross_val_scores(estimator,data,labels):\n",
    "    \"\"\" Evaluate the following merics: auc, precission, recall and f1 by Stratified 5-Folds cross-validation\n",
    "\n",
    "        Keyword arguments:\n",
    "            estimator -- estimator object implementing ‘fit’\n",
    "\n",
    "            data -- array-like of shape (n_samples, n_features)\n",
    "            The data to fit.\n",
    "\n",
    "            labels -- array-like of shape(n_samples)\n",
    "            The target variable to try to predict.\n",
    "        Returns:\n",
    "            auc_scores -- 1-d array of shape (50,) \n",
    "            Array of auc scores of the estimator for each run of the cross validation.\n",
    "            f_scores -- 1-d array of shape (50,) \n",
    "            Array of f1 scores of the estimator for each run of the cross validation.\n",
    "            pr_scores -- 1-d array of shape (50,) \n",
    "            Array of precission scores of the estimator for each run of the cross validation.\n",
    "            rec_scores -- 1-d array of shape (50,) \n",
    "            Array of recall scores of the estimator for each run of the cross validation.\n",
    "    \"\"\"\n",
    "    auc_scores = []\n",
    "    thresholds = []\n",
    "    pr_scores = []\n",
    "    rec_scores = []\n",
    "    f_scores = []\n",
    "    for i in range(10):\n",
    "        skf = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=i)\n",
    "        for train_indices, test_indices in skf.split(data, labels):\n",
    "            estimator.fit(data[train_indices,:], labels[train_indices])\n",
    "            auc_scores.append(metrics.roc_auc_score(labels[test_indices], \n",
    "                                        estimator.predict_proba(data[test_indices,:])[:,1]))\n",
    "\n",
    "            fpr, tpr, thr = metrics.roc_curve(labels[test_indices], \n",
    "                                        estimator.predict_proba(data[test_indices,:])[:,1])\n",
    "            norms = np.array([(np.linalg.norm([0,1] - np.array([f, t]))) for t, f in zip(tpr,fpr)])\n",
    "            thresholds.append(thr[np.argmin(norms)])\n",
    "\n",
    "            f_scores.append(metrics.f1_score(labels[test_indices],\n",
    "                                   [0 if p <thr[np.argmin(norms)] else 1 \n",
    "                                    for p in estimator.predict_proba(data[test_indices,:])[:,1]]))\n",
    "            pr_scores.append(metrics.precision_score(labels[test_indices],\n",
    "                                   [0 if p <thr[np.argmin(norms)] else 1 \n",
    "                                    for p in estimator.predict_proba(data[test_indices,:])[:,1]]))\n",
    "            rec_scores.append(metrics.recall_score(labels[test_indices],\n",
    "                                   [0 if p <thr[np.argmin(norms)] else 1 \n",
    "                                    for p in estimator.predict_proba(data[test_indices,:])[:,1]]))\n",
    "    return (auc_scores, f_scores, pr_scores, rec_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_scores = 0.6845, f_scores = 0.2057, pr_scores = 0.1226, rec_scores = 0.6416\n"
     ]
    }
   ],
   "source": [
    "auc_scores, f_scores, pr_scores, rec_scores = get_cross_val_scores(log_reg,data,labels)\n",
    "print('auc_scores = %0.4f, f_scores = %0.4f, pr_scores = %0.4f, rec_scores = %0.4f' %\n",
    "     (np.mean(auc_scores), np.mean(f_scores), np.mean(pr_scores), np.mean(rec_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построю pipeline для случайного леса и выведу среднее метрик на кроссвалидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = pl.Pipeline(steps=[\n",
    "    ('feature_processing', pl.FeatureUnion(transformer_list=[\n",
    "        #numeric\n",
    "        ('numeric_variable_processing',pl.Pipeline(steps=[\n",
    "            ('selecting', FunctionTransformer(lambda data: data[:,num_indices],validate=False)),\n",
    "            ('imputing_nan_values', SimpleImputer(missing_values=np.nan,strategy='mean',fill_value=0)),\n",
    "            ('converting', FunctionTransformer(lambda data: data.astype(np.float64),validate=False))\n",
    "        ])),\n",
    "        #categorial\n",
    "        ('categorial_variable_processing',pl.Pipeline(steps=[\n",
    "            ('selecting', FunctionTransformer(lambda data: data[:,cat_indices],validate=False)),\n",
    "            ('imputing_nan_values', SimpleImputer(missing_values=np.nan, strategy='constant', fill_value='na')),\n",
    "            ('encoding', ce.CatBoostEncoder())\n",
    "        ]))\n",
    "    ])),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, class_weight='balanced_subsample'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_scores = 0.6905, f_scores = 0.2132, pr_scores = 0.1284, rec_scores = 0.6323\n",
      "Wall time: 26min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "auc_scores, f_scores, pr_scores, rec_scores = get_cross_val_scores(rand_forest,data,labels)\n",
    "print('auc_scores = %0.4f, f_scores = %0.4f, pr_scores = %0.4f, rec_scores = %0.4f' %\n",
    "     (np.mean(auc_scores), np.mean(f_scores), np.mean(pr_scores), np.mean(rec_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построю pipeline для градиентого бустинга и выведу среднее метрик."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = pl.Pipeline(steps=[\n",
    "    ('feature_processing', pl.FeatureUnion(transformer_list=[\n",
    "        #numeric\n",
    "        ('numeric_variable_processing',pl.Pipeline(steps=[\n",
    "            ('selecting', FunctionTransformer(lambda data: data[:,num_indices],validate=False)),\n",
    "            ('imputing_nan_values', SimpleImputer(missing_values=np.nan,strategy='mean',fill_value=0)),\n",
    "            ('converting', FunctionTransformer(lambda data: data.astype(np.float64),validate=False))\n",
    "        ])),\n",
    "        #categorial\n",
    "        ('categorial_variable_processing',pl.Pipeline(steps=[\n",
    "            ('selecting', FunctionTransformer(lambda data: data[:,cat_indices],validate=False)),\n",
    "            ('imputing_nan_values', SimpleImputer(missing_values=np.nan, strategy='constant', fill_value='na')),\n",
    "            ('encoding', ce.CountEncoder(min_group_size=0.1))\n",
    "        ]))\n",
    "    ])),\n",
    "    ('classifier', XGBClassifier(scale_pos_weight=(len(labels)-sum(labels))/sum(labels),n_jobs=4))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_scores = 0.7376, f_scores = 0.2416, pr_scores = 0.1475, rec_scores = 0.6716\n"
     ]
    }
   ],
   "source": [
    "auc_scores, f_scores, pr_scores, rec_scores = get_cross_val_scores(xgb_clf,data,labels)\n",
    "print('auc_scores = %0.4f, f_scores = %0.4f, pr_scores = %0.4f, rec_scores = %0.4f' %\n",
    "     (np.mean(auc_scores), np.mean(f_scores), np.mean(pr_scores), np.mean(rec_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшие показатели у классификатора в основе которого алгоритм градиентного бустинга."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
